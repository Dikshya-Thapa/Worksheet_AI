{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "BeuEL_aSYZih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "SEJSV3ElXwjw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load & Observe Dataset"
      ],
      "metadata": {
        "id": "3G2z20YTx5sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"student.csv\")\n",
        "\n",
        "data.head()\n",
        "data.tail()\n",
        "data.info()\n",
        "data.describe()\n",
        "\n",
        "# Features (X) and Label/Target (Y)\n",
        "X = data[[\"Math\", \"Reading\"]].values.astype(float)\n",
        "Y = data[\"Writing\"].values.astype(float)\n",
        "\n",
        "print(\"X shape:\", X.shape)  # (n, 2)\n",
        "print(\"Y shape:\", Y.shape)  # (n,)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOEYmBRex6YS",
        "outputId": "a4fa7f24-a121-4fef-a8ca-4da9c54958b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n",
            "X shape: (1000, 2)\n",
            "Y shape: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Split Feature Matrix (X) and Target (Y)"
      ],
      "metadata": {
        "id": "wyO3XuU70Dp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# W (weights) for 2 features: Math, Reading\n",
        "W = np.zeros(X.shape[1])  # shape = (2,)\n",
        "\n",
        "# Prediction rule (no bias): y_pred = X dot W\n",
        "Y_pred_demo = X @ W\n",
        "\n",
        "print(\"W shape:\", W.shape)\n",
        "print(\"Example predictions shape:\", Y_pred_demo.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwTSVh5y0FDH",
        "outputId": "355f57e6-200a-44e2-e297-91d07fbe0ef1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W shape: (2,)\n",
            "Example predictions shape: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Train–Test Split (from scratch)"
      ],
      "metadata": {
        "id": "C5_4Z49k0Wxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_np(X, Y, test_size=0.2, random_state=42):\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    idx = np.arange(len(X))\n",
        "    rng.shuffle(idx)\n",
        "\n",
        "    test_n = int(len(X) * test_size)\n",
        "    test_idx = idx[:test_n]\n",
        "    train_idx = idx[test_n:]\n",
        "\n",
        "    return X[train_idx], X[test_idx], Y[train_idx], Y[test_idx]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split_np(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train:\", X_train.shape, Y_train.shape)\n",
        "print(\"Test :\", X_test.shape, Y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "8sqNDWxx0Xmt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d2c122-3f38-4aca-d378-92a13b0ea51e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (800, 2) (800,)\n",
            "Test : (200, 2) (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Cost Function (Mean Squared Error)"
      ],
      "metadata": {
        "id": "uPnLxdV40svl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(X, Y, W):\n",
        "    n = len(Y)\n",
        "    Y_pred = X @ W\n",
        "    cost = (1/(2*n)) * np.sum((Y_pred - Y)**2)\n",
        "    return cost\n",
        "\n"
      ],
      "metadata": {
        "id": "PV1N6gUP0wRR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Pass the given test case (cost must be 0)"
      ],
      "metadata": {
        "id": "HzFbkuty1Un1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_case = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "Y_test_case = np.array([3, 7, 11])\n",
        "W_test_case = np.array([1, 1])\n",
        "\n",
        "cost = cost_function(X_test_case, Y_test_case, W_test_case)\n",
        "\n",
        "if cost == 0:\n",
        "    print(\"Proceed Further\")\n",
        "else:\n",
        "    print(\"something went wrong: Reimplement a cost function\")\n",
        "    print(\"Cost function output:\", cost)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-fSyQVg1VYg",
        "outputId": "85125bff-9ca8-4ced-f1f6-ccbf69d2b12a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceed Further\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Gradient Descent (No Bias)"
      ],
      "metadata": {
        "id": "KbQ5Ame41vGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    n = len(Y)\n",
        "    cost_history = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        Y_pred = X @ W\n",
        "        gradient = (1/n) * (X.T @ (Y_pred - Y))\n",
        "        W = W - alpha * gradient\n",
        "        cost_history.append(cost_function(X, Y, W))\n",
        "\n",
        "    return W, np.array(cost_history)\n",
        "\n"
      ],
      "metadata": {
        "id": "JSstXuGI17df"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To-Do-7: Train model (run GD)"
      ],
      "metadata": {
        "id": "_zuz348Q2M-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W_init = np.zeros(X_train.shape[1])\n",
        "alpha = 0.00001\n",
        "iterations = 1000\n",
        "\n",
        "W_optimal, cost_history = gradient_descent(X_train, Y_train, W_init, alpha, iterations)\n",
        "\n",
        "print(\"Final W:\", W_optimal)\n",
        "print(\"First 10 costs:\", cost_history[:10])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbceeWSM2OZv",
        "outputId": "0a421b84-4e78-4110-a060-37fb5c6548b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final W: [0.35107246 0.64360849]\n",
            "First 10 costs: [1992.85006903 1628.24690693 1330.93045861 1088.48291521  890.77818311\n",
            "  729.55894631  598.0917822   490.88592601  403.4639374   332.17469078]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. RMSE"
      ],
      "metadata": {
        "id": "QGt-38cX2Zjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(Y, Y_pred):\n",
        "    return np.sqrt(np.mean((Y_pred - Y)**2))\n",
        "\n"
      ],
      "metadata": {
        "id": "NBzRiseK2xnX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. R² Score"
      ],
      "metadata": {
        "id": "ZOzRJEFRQ2fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def r2(Y, Y_pred):\n",
        "    mean_y = np.mean(Y)\n",
        "    ss_tot = np.sum((Y - mean_y)**2)\n",
        "    ss_res = np.sum((Y - Y_pred)**2)\n",
        "    return 1 - (ss_res / ss_tot)\n",
        "\n"
      ],
      "metadata": {
        "id": "iA__LgLLRN3h"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To-Do-10: Main function"
      ],
      "metadata": {
        "id": "tIx8LfwjS94g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    data = pd.read_csv(\"student.csv\")\n",
        "\n",
        "    X = data[[\"Math\", \"Reading\"]].values.astype(float)\n",
        "    Y = data[\"Writing\"].values.astype(float)\n",
        "\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split_np(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    W = np.zeros(X_train.shape[1])\n",
        "    alpha = 0.00001\n",
        "    iterations = 1000\n",
        "\n",
        "    W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "\n",
        "    Y_pred = X_test @ W_optimal\n",
        "\n",
        "    model_rmse = rmse(Y_test, Y_pred)\n",
        "    model_r2 = r2(Y_test, Y_pred)\n",
        "\n",
        "    print(\"Final Weights:\", W_optimal)\n",
        "    print(\"Cost History (First 10):\", cost_history[:10])\n",
        "    print(\"RMSE on Test Set:\", model_rmse)\n",
        "    print(\"R-Squared on Test Set:\", model_r2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4gANu3eS_Sa",
        "outputId": "d7a31638-bf80-4239-f413-4f41297cf6ee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.35107246 0.64360849]\n",
            "Cost History (First 10): [1992.85006903 1628.24690693 1330.93045861 1088.48291521  890.77818311\n",
            "  729.55894631  598.0917822   490.88592601  403.4639374   332.17469078]\n",
            "RMSE on Test Set: 5.131334826568035\n",
            "R-Squared on Test Set: 0.8889734095560186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To-Do-11: Findings (overfit/underfit + learning rate experiment)"
      ],
      "metadata": {
        "id": "VrfQQsT-Wdmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Model Performance Analysis"
      ],
      "metadata": {
        "id": "jEHFOgUnWjJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance of the linear regression model is acceptable.\n",
        "\n",
        "The model does not overfit because the training and test errors are close to each other.\n",
        "\n",
        "The model does not underfit because it is able to learn a strong relationship between the features (Math and Reading) and the target (Writing).\n",
        "\n",
        "The obtained RMSE is reasonably low, and the R² value is high, indicating that the model explains most of the variance in the writing scores.\n",
        "\n",
        "Conclusion:\n",
        "The model generalizes well and its performance is acceptable."
      ],
      "metadata": {
        "id": "l6jj4b6LXOCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Effect of Learning Rate"
      ],
      "metadata": {
        "id": "4yk5p8RCXQ1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different learning rates were tested to observe their effect on model convergence and performance.\n",
        "\n",
        "Very small learning rate (e.g., 0.000001):\n",
        "The model learns very slowly and requires many iterations to converge, leading to underfitting.\n",
        "\n",
        "Moderate learning rate (e.g., 0.00001):\n",
        "The model converges smoothly and provides the best performance with stable cost reduction.\n",
        "\n",
        "High learning rate (e.g., 0.001):\n",
        "The cost function becomes unstable and may diverge, resulting in poor model performance.\n",
        "\n",
        "Observation:\n",
        "Choosing an appropriate learning rate is crucial. A moderate learning rate ensures stable convergence and optimal model performance."
      ],
      "metadata": {
        "id": "e3zhe640XTMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Conclusion"
      ],
      "metadata": {
        "id": "-NolRagJXWfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The linear regression model shows acceptable performance. Proper selection of the learning rate significantly affects the convergence behavior and accuracy of the model."
      ],
      "metadata": {
        "id": "yy9_2lBiXZmr"
      }
    }
  ]
}